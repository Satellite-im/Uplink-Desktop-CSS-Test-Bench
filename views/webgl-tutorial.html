<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
    <head>
        <link rel="stylesheet" href="/static/tools.css" type="text/css">
    </head>
<body style="display:flex; flex-direction:column; justify-content:space-between;">
    <span>video player</span>
    <canvas id="canvas" width="512" height="512">Browser doesn't support canvas. </canvas>
    <button onclick="play()">start</button>
    <script type="text/javascript" src="/webgl/webgl-utils.js"></script>
    <script type="text/javascript">

let first_click = false;
function play() {
    if (first_click === false) {
        first_click = true;
    } else {
        return;
    }
}

// glsl scripts and webgl2 adapted from this blog post: https://medium.com/docler-engineering/webgl-video-manipulation-8d0892b565b6
// chatgpt "helped" a little here too 

// stores the gl object
var glRef = {};
var programRef = {};
// the opengl texture, which is bound using gl.bindTexture() and then assigned to using the uniforms
var textures = {};
var attributes = {};
var buffers = {};
var uniforms = {};

const vertexShaderSource = `#version 300 es
attribute vec2 a_position;
attribute vec2 a_texCoord;
uniform vec2 u_resolution; 
varying vec2 v_texCoord;
  
void main() {  
    gl_Position =  vec4(( (a_position / u_resolution * 2.0) - 1.0)  * vec2(1, -1), 0, 1);
    v_texCoord = a_texCoord;
}
`;

const fragmentShaderSource = `#version 300 es
precision highp float;

uniform sampler2D u_image_frame;
uniform vec2 u_resolution;
varying vec2 v_texCoord;

void main() {
    float x_offset = mod( gl_FragCoord.y ,2.0  ) < 1.0 ? 0.5 : 0.0 ;
    vec4 y4 =  texture2D(u_image_frame, vec2 ( v_texCoord.x / 1.0  , v_texCoord.y / 1.5  )   )  ;
    vec4 u4 = (texture2D(u_image_frame, vec2 ( x_offset + v_texCoord.x  / 2.0  ,2.0/3.0 +  v_texCoord.y / 6.0  )   ) -0.50 ) * 2.0 ;
    vec4 v4 = (texture2D(u_image_frame, vec2 ( x_offset + v_texCoord.x / 2.0  , 5.0/6.0 + v_texCoord.y / 6.0  )   ) -0.50 ) * 2.0 ;

    float y = y4[0] ;
    float u = u4[0] ;
    float v = v4[0] ;

    float R = clamp(y + 1.13 * v, 0.0, 1.0) ;
    float G = clamp(y - 0.39 * u - 0.58 * v, 0.0, 1.0) ;
    float B = clamp(y + 2.03 * u, 0.0, 1.0) ;

    vec4 video_pixel = vec4( vec3(R,G,B), 1.0) ;
    gl_FragColor = video_pixel ;
}
`;

function createShader(gl, type, source) {
    const shader = gl.createShader(type);
    gl.shaderSource(shader, source);
    gl.compileShader(shader);

    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        console.error(`Shader compilation error: ${gl.getShaderInfoLog(shader)}`);
        gl.deleteShader(shader);
        return null;
    }

    return shader;
}

function createProgram(gl, vertexShaderSource, fragmentShaderSource) {
    const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
    const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);

    if (!vertexShader || !fragmentShader) {
        return null;
    }

    const program = gl.createProgram();
    gl.attachShader(program, vertexShader);
    gl.attachShader(program, fragmentShader);
    gl.linkProgram(program);

    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error(`Program linking error: ${gl.getProgramInfoLog(program)}`);
        gl.deleteProgram(program);
        return null;
    }

    return program;
}

function initBuffers(gl) {
    const positionBuffer = gl.createBuffer();
    buffers.positionBuffer = positionBuffer;

    const texcoordBuffer = gl.createBuffer();
    buffers.texcoordBuffer = texcoordBuffer;

    gl.bindBuffer(gl.ARRAY_BUFFER,  buffers.positionBuffer);

    // Set a rectangle the same size as the image.
    const x1 = 0;
    const x2 = 0 + width;
    const y1 = 0;
    const y2 = 0 + height;
    gl.bufferData(
        gl.ARRAY_BUFFER,
        new Float32Array([x1, y1, x2, y1, x1, y2, x1, y2, x2, y1, x2, y2]),
        gl.STATIC_DRAW
    );

    // provide texture coordinates for the rectangle.
    gl.bindBuffer(gl.ARRAY_BUFFER,  buffers.texcoordBuffer);
    gl.bufferData(
    gl.ARRAY_BUFFER,
    new Float32Array([
        0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0,
        ]),
        gl.STATIC_DRAW
    );
}

function initTexture(gl) {
    // gl.bindTexture means 'apply all following texture functions to this texture'
    // TEXTURE_MIN_FILTER determines how texture data is sampled when the texture is smaller than the source image
    // TEXTURE_MAG_FILTER ''                                                         larger than the source image

    const texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

    textures.zero = texture;
}

function init() {
    const canvas = document.querySelector("#canvas") || document.createElement("canvas");
    canvas.width = 512;
    canvas.height = 512;

    const gl = canvas.getContext("webgl2");
    if (!gl) {
        console.error("Unable to initialize WebGL. Your browser may not support it.");
        return;
    }
   
    const program = createProgram(gl, vertexShaderSource, fragmentShaderSource);
    gl.useProgram(program);
    programRef.program = program;

    // init attributes
    // canvas vs image
    const positionLocation = gl.getAttribLocation(program, "a_position");
    attributes.positionLocation = positionLocation;
    // texture vs image
    const texcoordLocation = gl.getAttribLocation(program, "a_texCoord");
    attributes.texcoordLocation = texcoordLocation;

    initBuffers(gl);
    initTexture(gl);

    const u_image_frame = gl.getUniformLocation(program, "u_image_frame");
    gl.uniform1i(u_image_frame, 0); // texture unit 0
    uniforms.image_frame = u_image_frame;

    // set which texture units to render with.
    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, textures.zero);

    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
    gl.clearColor(0, 0, 0, 0);
    gl.clear(gl.COLOR_BUFFER_BIT);

    // Turn on the position attribute
    gl.enableVertexAttribArray(attributes.positionLocation);

    // Bind the position buffer.
    gl.bindBuffer(gl.ARRAY_BUFFER, buffers.positionBuffer);

    // Tell the position attribute how to get data out of positionBuffer (ARRAY_BUFFER)
    {
        const size = 2;
        const type = gl.FLOAT;
        const normalize = false;
        const stride = 0;
        const offset = 0;
        gl.vertexAttribPointer(
            positionLocation,
            size,
            type,
            normalize,
            stride,
            offset
        );
    }

    // Turn on the texcoord attribute
    gl.enableVertexAttribArray(attributes.texcoordLocation);

    // bind the texcoord buffer.
    gl.bindBuffer(gl.ARRAY_BUFFER, buffers.texcoordBuffer);

    // Tell the texcoord attribute how to get data out of texcoordBuffer (ARRAY_BUFFER)
    {
        const size = 2;
        const type = gl.FLOAT;
        const normalize = false;
        const stride = 0;
        const offset = 0;
        gl.vertexAttribPointer(
            texcoordLocation,
            size,
            type,
            normalize,
            stride,
            offset
        );
    }

    // lookup uniforms
    const resolutionLocation = gl.getUniformLocation(program, "u_resolution");
    // set the resolution
    gl.uniform2f(resolutionLocation, gl.canvas.width, gl.canvas.height);

    // Draw the rectangle.
    gl.drawArrays(gl.TRIANGLES, 0, 6);

    glRef.gl = gl;
}

function render(data, width, height) {
    // Assuming you have the Y, U, and V components in separate arrays 
    glRef.gl.bindTexture(gl.TEXTURE_2D, textures.zero);
    glRef.gl.texImage2D(
        glRef.gl.TEXTURE_2D, 
        0, 
        gl.LUMINANCE, 
        width, 
        height * 1.5, 
        0, 
        gl.LUMINANCE, 
        gl.UNSIGNED_BYTE, 
        data
    );
   
    glRef.gl.clear(glRef.gl.COLOR_BUFFER_BIT);
    glRef.gl.drawArrays(glRef.gl.TRIANGLES, 0, 6);
}

init();

// todo: receive images and call render()
// left off here: https://chat.openai.com/c/f4829fe9-0ff2-42a6-bb40-9b0fd98ad6c4

    </script>
</body>
</html>